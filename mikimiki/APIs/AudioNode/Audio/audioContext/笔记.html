<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Title</title>
</head>
<body>
<information>
    AudioContext接口表示由链接在一起的音频模块构建的音频处理图，每个模块由一个AudioNode表示。
    音频上下文控制它包含的节点的创建和音频处理或解码的执行。在做任何其他操作之前，您需要创建一个AudioContext对象，
    因为所有事情都是在上下文中发生的。建议创建一个AudioContext对象并复用它，
    而不是每次初始化一个新的AudioContext对象，并且可以对多个不同的音频源和管道同时使用一个AudioContext对象。
</information>
<constructor>
    <script type="text/javascript">
        document.addEventListener("DOMContentLoaded",function (){
            let ac = AudioContext();
        })
    </script>
</constructor>
<property>
    AudioContext.baseLatency 只读
    返回AudioContext将音频从AudioDestinationNode传递到音频子系统的处理延迟的秒数。

    AudioContext.outputLatency 只读
    返回对当前音频上下文的预估输出延迟。
</property>
<method>
    AudioContext.close()
    关闭一个音频环境, 释放任何正在使用系统资源的音频。

    AudioContext.createMediaElementSource()
    创建一个MediaElementAudioSourceNode接口来关联HTMLMediaElement.
    这可以用来播放和处理来自<video>或<audio> 元素的音频。

    AudioContext.createMediaStreamSource()
    创建一个MediaStreamAudioSourceNode接口来关联可能来自本地计算机麦克风或其他来源的音频流MediaStream。

    AudioContext.createMediaStreamDestination()
    创建一个MediaStreamAudioDestinationNode接口来关联可能储存在本地或已发送至其他计算机的MediaStream音频。

    AudioContext.createMediaStreamTrackSource()
    创建一个MediaStreamTrackAudioSourceNode，它与一个MediaStream相关联，表示一个媒体流轨迹。

    AudioContext.getOutputTimestamp()
    返回一个新的AudioTimestamp对象，该对象包含两个与当前音频上下文相关的音频时间戳。

    AudioContext.resume()
    恢复之前被暂停的音频上下文中的时间进程。

    AudioContext.suspend()
    暂停音频上下文中的时间进程，暂停音频硬件访问并减少进程中的CPU/电池使用。
</method>
</body>
</html>